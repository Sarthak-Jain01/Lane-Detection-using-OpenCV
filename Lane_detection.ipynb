{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lane detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N25BG_FmGSX"
      },
      "source": [
        "#Lane Lines Detection Using Python and OpenCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFLg-W68mQ2q"
      },
      "source": [
        "In this project, I used Python and OpenCV to detect lane lines on the road. I developed a processing pipeline that works on a series of individual images, and applied the result to a video stream."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u36oveZCmiGg"
      },
      "source": [
        "#1. Loading test images:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrMevNuvmnKY"
      },
      "source": [
        "A function called list_images() that shows all the test images we're working on using matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCcCokNQo3TE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ebf6f0d-135d-46c4-a15f-c75a3b57499e"
      },
      "source": [
        "#Importing some useful packages\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b892928/45929032 bytes (1.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2441216/45929032 bytes (5.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4497408/45929032 bytes (9.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b7086080/45929032 bytes (15.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b10166272/45929032 bytes (22.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b13475840/45929032 bytes (29.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16539648/45929032 bytes (36.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20103168/45929032 bytes (43.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23322624/45929032 bytes (50.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b26763264/45929032 bytes (58.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b30040064/45929032 bytes (65.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b33325056/45929032 bytes (72.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b36421632/45929032 bytes (79.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b39559168/45929032 bytes (86.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b42680320/45929032 bytes (92.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCTQFbpjmvgi"
      },
      "source": [
        "def list_images(images, cols = 2, rows = 5, cmap=None):\n",
        "    \"\"\"\n",
        "    Display a list of images in a single figure with matplotlib.\n",
        "        Parameters:\n",
        "            images: List of np.arrays compatible with plt.imshow.\n",
        "            cols (Default = 2): Number of columns in the figure.\n",
        "            rows (Default = 5): Number of rows in the figure.\n",
        "            cmap (Default = None): Used to display gray images.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 11))\n",
        "    for i, image in enumerate(images):\n",
        "        plt.subplot(rows, cols, i+1)\n",
        "        #Use gray scale color map if there is only one channel\n",
        "        cmap = 'gray' if len(image.shape) == 2 else cmap\n",
        "        plt.imshow(image, cmap = cmap)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "    plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xy5PF9_peL9"
      },
      "source": [
        "Reading in the test images\n",
        "test_images = [plt.imread(img) for img in glob.glob('test_images/*.jpg')]\n",
        "list_images(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxUHd0bfnF5i"
      },
      "source": [
        "# 2. Color Selection:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z4M0Fo0nHna"
      },
      "source": [
        "Since the Lane lines present in the test images are in white and yellow so we need to choose the most suitable color space, that clearly highlights the lane lines. I applied color selection to the original RGB images, HSV images, and HSL images, and found out that using HSL will be the best color space to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1_YXoPziTdg"
      },
      "source": [
        "#a) Original RGB color selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8lKa9RDiVL0"
      },
      "source": [
        "We try to retain as much of the lane lines as possible, while blacking out most of the other stuff."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_R5bxGsnHvI"
      },
      "source": [
        "def HSL_color_selection(image):\n",
        "    \"\"\"\n",
        "    Apply color selection to the HSL images to blackout everything except for white and yellow lane lines.\n",
        "        Parameters:\n",
        "            image: An np.array compatible with plt.imshow.\n",
        "    \"\"\"\n",
        "    #Convert the input image to HSL\n",
        "    converted_image = convert_hsl(image)\n",
        "    \n",
        "    #White color mask\n",
        "    lower_threshold = np.uint8([0, 200, 0])\n",
        "    upper_threshold = np.uint8([255, 255, 255])\n",
        "    white_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
        "    \n",
        "    #Yellow color mask\n",
        "    lower_threshold = np.uint8([10, 0, 100])\n",
        "    upper_threshold = np.uint8([40, 255, 255])\n",
        "    yellow_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
        "    \n",
        "    #Combine white and yellow masks\n",
        "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
        "    masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
        "    \n",
        "    return masked_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1w0o_tIq6IA"
      },
      "source": [
        "Applying color selection to test_images in the RGB color space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqklJU53q3ou"
      },
      "source": [
        "list_images(list(map(RGB_color_selection, test_images)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNeNND_-YAVW"
      },
      "source": [
        "\n",
        "#b) HSV color space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_aSdqP5YEGf"
      },
      "source": [
        "HSV is an alternative representation of the RGB color model. The HSV representation models the way colors mix together, with the saturation dimension resembling various shades of brightly colored paint, and the value dimension resembling the mixture of those paints with varying amounts of black or white."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPop259LYKGn"
      },
      "source": [
        "def convert_hsv(image):\n",
        "    \"\"\"\n",
        "    Convert RGB images to HSV.\n",
        "        Parameters:\n",
        "            image: An np.array compatible with plt.imshow.\n",
        "    \"\"\"\n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "list_images(list(map(convert_hsv, test_images)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx5DdWKsite_"
      },
      "source": [
        "def HSV_color_selection(image):\n",
        "    \"\"\"\n",
        "    Apply color selection to the HSV images to blackout everything except for white and yellow lane lines.\n",
        "        Parameters:\n",
        "            image: An np.array compatible with plt.imshow.\n",
        "    \"\"\"\n",
        "    #Convert the input image to HSV\n",
        "    converted_image = convert_hsv(image)\n",
        "    \n",
        "    #White color mask\n",
        "    lower_threshold = np.uint8([0, 0, 210])\n",
        "    upper_threshold = np.uint8([255, 30, 255])\n",
        "    white_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
        "    \n",
        "    #Yellow color mask\n",
        "    lower_threshold = np.uint8([18, 80, 80])\n",
        "    upper_threshold = np.uint8([30, 255, 255])\n",
        "    yellow_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
        "    \n",
        "    #Combine white and yellow masks\n",
        "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
        "    masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
        "    \n",
        "    return masked_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zONqETGqixYV"
      },
      "source": [
        "list_images(list(map(HSV_color_selection, test_images)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBIJ6SaBi1b3"
      },
      "source": [
        "#c) HSL color space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RE7uVbMi_gN"
      },
      "source": [
        "HSL is an alternative representation of the RGB color model. The HSL model attempts to resemble more perceptual color models such as NCS or Munsell, placing fully saturated colors around a circle at a lightness value of 1/2, where a lightness value of 0 or 1 is fully black or white, respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNC_xqcBi-h5"
      },
      "source": [
        "def convert_hsl(image):\n",
        "    \"\"\"\n",
        "    Convert RGB images to HSL.\n",
        "        Parameters:\n",
        "            image: An np.array compatible with plt.imshow.\n",
        "    \"\"\"\n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
        "\n",
        "list_images(list(map(convert_hsl, test_images)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9uI7dz9jHZf"
      },
      "source": [
        "def HSL_color_selection(image):\n",
        "    \"\"\"\n",
        "    Apply color selection to the HSL images to blackout everything except for white and yellow lane lines.\n",
        "        Parameters:\n",
        "            image: An np.array compatible with plt.imshow.\n",
        "    \"\"\"\n",
        "    #Convert the input image to HSL\n",
        "    converted_image = convert_hsl(image)\n",
        "    \n",
        "    #White color mask\n",
        "    lower_threshold = np.uint8([0, 200, 0])\n",
        "    upper_threshold = np.uint8([255, 255, 255])\n",
        "    white_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
        "    \n",
        "    #Yellow color mask\n",
        "    lower_threshold = np.uint8([10, 0, 100])\n",
        "    upper_threshold = np.uint8([40, 255, 255])\n",
        "    yellow_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
        "    \n",
        "    #Combine white and yellow masks\n",
        "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
        "    masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
        "    \n",
        "    return masked_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrxdCg5hjHm_"
      },
      "source": [
        "list_images(list(map(HSL_color_selection, test_images)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-BRfBcqneg9"
      },
      "source": [
        "# 3. Canny Edge Detection:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0_ki2MYngdW"
      },
      "source": [
        "We need to detect edges in the images to be able to correctly detect lane lines. The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. The Canny algorithm involves the following steps:\n",
        "of the image.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8At-Y0nhjnZc"
      },
      "source": [
        "#a) Gray scaling the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m9R2U8hjpDw"
      },
      "source": [
        "\n",
        "The Canny edge detection algorithm measures the intensity gradients of each pixel. So, we need to convert the images into gray scale in order to detect edges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBMEbXRzjjTt"
      },
      "source": [
        "def gray_scale(image):\n",
        "    \"\"\"\n",
        "    Convert images to gray scale.\n",
        "        Parameters:\n",
        "            image: An np.array compatible with plt.imshow.\n",
        "    \"\"\"\n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xMyzZi1j3Qa"
      },
      "source": [
        "gray_images = list(map(gray_scale, color_selected_images))\n",
        "list_images(gray_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bggqMBgtj6hz"
      },
      "source": [
        "#b) Applying Gaussian smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJlfX_5Qj9ve"
      },
      "source": [
        " Since all edge detection results are easily affected by image noise, it is essential to filter out the noise to prevent false detection caused by noise. To smooth the image, a Gaussian filter is applied to convolve with the image. This step will slightly smooth the image to reduce the effects of obvious noise on the edge detector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpaCqmXakAjU"
      },
      "source": [
        "def gaussian_smoothing(image, kernel_size = 13):\n",
        "    \"\"\"\n",
        "    Apply Gaussian filter to the input image.\n",
        "        Parameters:\n",
        "            image: An np.array compatible with plt.imshow.\n",
        "            kernel_size (Default = 13): The size of the Gaussian kernel will affect the performance of the detector.\n",
        "            It must be an odd number (3, 5, 7, ...).\n",
        "    \"\"\"\n",
        "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8QbOrjdkDWF"
      },
      "source": [
        "blur_images = list(map(gaussian_smoothing, gray_images))\n",
        "list_images(blur_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UNw4_pskHbE"
      },
      "source": [
        "#c) Applying Canny Edge Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eywf430MkJNJ"
      },
      "source": [
        "The Process of Canny edge detection algorithm can be broken down to 5 different steps:\n",
        "\n",
        "1. Find the intensity gradients of the image\n",
        "2. Apply non-maximum suppression to get rid of spurious response to edge detection.\n",
        "3. Apply double threshold to determine potential edges.\n",
        "4. Track edge by hysteresis: Finalize the detection of edges by suppressing all the other edges that are weak and not connected to strong edges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiJaD7qZkL0j"
      },
      "source": [
        "def canny_detector(image, low_threshold = 50, high_threshold = 150):\n",
        "    \"\"\"\n",
        "    Apply Canny Edge Detection algorithm to the input image.\n",
        "        Parameters:\n",
        "            image: An np.array compatible with plt.imshow.\n",
        "            low_threshold (Default = 50).\n",
        "            high_threshold (Default = 150).\n",
        "    \"\"\"\n",
        "    return cv2.Canny(image, low_threshold, high_threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap3OIeyjkX3F"
      },
      "source": [
        "edge_detected_images = list(map(canny_detector, blur_images))\n",
        "list_images(edge_detected_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC1eGv9Fnkax"
      },
      "source": [
        "# 4. Region of interest:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr9HYStNnqst"
      },
      "source": [
        "We're interested only in the area facing the camera, where the lane lines are found. So, we'll apply region masking to cut out everything else."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPh2pSFznyQe"
      },
      "source": [
        "def region_selection(image):\n",
        "    \"\"\"\n",
        "    Determine and cut the region of interest in the input image.\n",
        "        Parameters:\n",
        "            image: An np.array compatible with plt.imshow.\n",
        "    \"\"\"\n",
        "    mask = np.zeros_like(image)   \n",
        "    #Defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
        "    if len(image.shape) > 2:\n",
        "        channel_count = image.shape[2]\n",
        "        ignore_mask_color = (255,) * channel_count\n",
        "    else:\n",
        "        ignore_mask_color = 255\n",
        "    #We could have used fixed numbers as the vertices of the polygon,\n",
        "    #but they will not be applicable to images with different dimesnions.\n",
        "    rows, cols = image.shape[:2]\n",
        "    bottom_left  = [cols * 0.1, rows * 0.95]\n",
        "    top_left     = [cols * 0.4, rows * 0.6]\n",
        "    bottom_right = [cols * 0.9, rows * 0.95]\n",
        "    top_right    = [cols * 0.6, rows * 0.6]\n",
        "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
        "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
        "    masked_image = cv2.bitwise_and(image, mask)\n",
        "    return masked_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ceqODFTkdhY"
      },
      "source": [
        "masked_image = list(map(region_selection, edge_detected_images))\n",
        "list_images(masked_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2XRyskmn3L5"
      },
      "source": [
        "# 5. Hough Transform:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiN2psaWn4rL"
      },
      "source": [
        "The Hough transform is a technique which can be used to isolate features of a particular shape within an image. I'll use it to detected the lane lines in selected_region_images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG5hOkDZn7lU"
      },
      "source": [
        "def hough_transform(image):\n",
        "    \"\"\"\n",
        "    Determine and cut the region of interest in the input image.\n",
        "        Parameters:\n",
        "            image: The output of a Canny transform.\n",
        "    \"\"\"\n",
        "    rho = 1              #Distance resolution of the accumulator in pixels.\n",
        "    theta = np.pi/180    #Angle resolution of the accumulator in radians.\n",
        "    threshold = 20       #Only lines that are greater than threshold will be returned.\n",
        "    minLineLength = 20   #Line segments shorter than that are rejected.\n",
        "    maxLineGap = 300     #Maximum allowed gap between points on the same line to link them\n",
        "    return cv2.HoughLinesP(image, rho = rho, theta = theta, threshold = threshold,\n",
        "                           minLineLength = minLineLength, maxLineGap = maxLineGap)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoDnY13ekj5c"
      },
      "source": [
        "hough_lines = list(map(hough_transform, masked_image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kngVBOnekkhY"
      },
      "source": [
        "\n",
        "def draw_lines(image, lines, color = [255, 0, 0], thickness = 2):\n",
        "    \"\"\"\n",
        "    Draw lines onto the input image.\n",
        "        Parameters:\n",
        "            image: An np.array compatible with plt.imshow.\n",
        "            lines: The lines we want to draw.\n",
        "            color (Default = red): Line color.\n",
        "            thickness (Default = 2): Line thickness.\n",
        "    \"\"\"\n",
        "    image = np.copy(image)\n",
        "    for line in lines:\n",
        "        for x1,y1,x2,y2 in line:\n",
        "            cv2.line(image, (x1, y1), (x2, y2), color, thickness)\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgcqbQD3ks1J"
      },
      "source": [
        "line_images = []\n",
        "for image, lines in zip(test_images, hough_lines):\n",
        "    line_images.append(draw_lines(image, lines))\n",
        "    \n",
        "list_images(line_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4GF_6IvoJIB"
      },
      "source": [
        "# 6. Averaging and extrapolating the lane lines:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKlp84wToLBm"
      },
      "source": [
        "We have multiple lines detected for each lane line. We need to average all these lines and draw a single line for each lane line. We also need to extrapolate the lane lines to cover the full lane line length.\n",
        "\n",
        "The left lane should have a negative slope (given that y coordinate is reversed in the images), and the right lane should have a negative slope. Therefore, we'll collect positive slope lines and negative slope lines separately and take averages. After calculating the average slope and intercept of each lane line, we'll convert these values to pixel points, and then we'll be able to draw the full length lane line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22g9aRgdoRaR"
      },
      "source": [
        "def average_slope_intercept(lines):\n",
        "    \"\"\"\n",
        "    Find the slope and intercept of the left and right lanes of each image.\n",
        "        Parameters:\n",
        "            lines: The output lines from Hough Transform.\n",
        "    \"\"\"\n",
        "    left_lines    = [] #(slope, intercept)\n",
        "    left_weights  = [] #(length,)\n",
        "    right_lines   = [] #(slope, intercept)\n",
        "    right_weights = [] #(length,)\n",
        "    \n",
        "    for line in lines:\n",
        "        for x1, y1, x2, y2 in line:\n",
        "            if x1 == x2:\n",
        "                continue\n",
        "            slope = (y2 - y1) / (x2 - x1)\n",
        "            intercept = y1 - (slope * x1)\n",
        "            length = np.sqrt(((y2 - y1) ** 2) + ((x2 - x1) ** 2))\n",
        "            if slope < 0:\n",
        "                left_lines.append((slope, intercept))\n",
        "                left_weights.append((length))\n",
        "            else:\n",
        "                right_lines.append((slope, intercept))\n",
        "                right_weights.append((length))\n",
        "    left_lane  = np.dot(left_weights,  left_lines) / np.sum(left_weights)  if len(left_weights) > 0 else None\n",
        "    right_lane = np.dot(right_weights, right_lines) / np.sum(right_weights) if len(right_weights) > 0 else None\n",
        "    return left_lane, right_lane\n",
        "\n",
        "def pixel_points(y1, y2, line):\n",
        "    \"\"\"\n",
        "    Converts the slope and intercept of each line into pixel points.\n",
        "        Parameters:\n",
        "            y1: y-value of the line's starting point.\n",
        "            y2: y-value of the line's end point.\n",
        "            line: The slope and intercept of the line.\n",
        "    \"\"\"\n",
        "    if line is None:\n",
        "        return None\n",
        "    slope, intercept = line\n",
        "    x1 = int((y1 - intercept)/slope)\n",
        "    x2 = int((y2 - intercept)/slope)\n",
        "    y1 = int(y1)\n",
        "    y2 = int(y2)\n",
        "    return ((x1, y1), (x2, y2))\n",
        "\n",
        "def lane_lines(image, lines):\n",
        "    \"\"\"\n",
        "    Create full lenght lines from pixel points.\n",
        "        Parameters:\n",
        "            image: The input test image.\n",
        "            lines: The output lines from Hough Transform.\n",
        "    \"\"\"\n",
        "    left_lane, right_lane = average_slope_intercept(lines)\n",
        "    y1 = image.shape[0]\n",
        "    y2 = y1 * 0.6\n",
        "    left_line  = pixel_points(y1, y2, left_lane)\n",
        "    right_line = pixel_points(y1, y2, right_lane)\n",
        "    return left_line, right_line\n",
        "    \n",
        "def draw_lane_lines(image, lines, color=[255, 0, 0], thickness=12):\n",
        "    \"\"\"\n",
        "    Draw lines onto the input image.\n",
        "        Parameters:\n",
        "            image: The input test image.\n",
        "            lines: The output lines from Hough Transform.\n",
        "            color (Default = red): Line color.\n",
        "            thickness (Default = 12): Line thickness. \n",
        "    \"\"\"\n",
        "    line_image = np.zeros_like(image)\n",
        "    for line in lines:\n",
        "        if line is not None:\n",
        "            cv2.line(line_image, *line,  color, thickness)\n",
        "    return cv2.addWeighted(image, 1.0, line_image, 1.0, 0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BheAVNxoSTy"
      },
      "source": [
        "# 7. Apply on video streams:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLNExBB9oWSE"
      },
      "source": [
        "Now, we'll use the above functions to detect lane lines from a video stream. The video inputs are in test_videos folder. The video outputs are generated in output_videos folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEdv0eAMobXD"
      },
      "source": [
        "def frame_processor(image):\n",
        "    \"\"\"\n",
        "    Process the input frame to detect lane lines.\n",
        "        Parameters:\n",
        "            image: Single video frame.\n",
        "    \"\"\"\n",
        "    color_select = HSL_color_selection(image)\n",
        "    gray         = gray_scale(color_select)\n",
        "    smooth       = gaussian_smoothing(gray)\n",
        "    edges        = canny_detector(smooth)\n",
        "    region       = region_selection(edges)\n",
        "    hough        = hough_transform(region)\n",
        "    result       = draw_lane_lines(image, lane_lines(image, hough))\n",
        "    return result\n",
        "\n",
        "def process_video(test_video, output_video):\n",
        "    \"\"\"\n",
        "    Read input video stream and produce a video file with detected lane lines.\n",
        "        Parameters:\n",
        "            test_video: Input video.\n",
        "            output_video: A video file with detected lane lines.\n",
        "    \"\"\"\n",
        "    input_video = VideoFileClip(os.path.join('test_videos', test_video), audio=False)\n",
        "    processed = input_video.fl_image(frame_processor)\n",
        "    processed.write_videofile(os.path.join('output_videos', output_video), audio=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMF7daN6k9jc"
      },
      "source": [
        "%time process_video('solidWhiteRight.mp4', 'solidWhiteRight_output.mp4')\n",
        "HTML(\"\"\"\n",
        "<video width=\"960\" height=\"540\" controls>\n",
        "  <source src=\"{0}\">\n",
        "</video>\n",
        "\"\"\".format(\"output_videos\\solidWhiteRight_output.mp4\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWy5okv4lAzA"
      },
      "source": [
        "%time process_video('solidWhiteRight.mp4', 'solidWhiteRight_output.mp4')\n",
        "HTML(\"\"\"\n",
        "<video width=\"960\" height=\"540\" controls>\n",
        "  <source src=\"{0}\">\n",
        "</video>\n",
        "\"\"\".format(\"output_videos\\solidWhiteRight_output.mp4\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDQBvrSblA2O"
      },
      "source": [
        "%time process_video('challenge.mp4', 'challenge_output.mp4')\n",
        "HTML(\"\"\"\n",
        "<video width=\"960\" height=\"540\" controls>\n",
        "  <source src=\"{0}\">\n",
        "</video>\n",
        "\"\"\".format(\"output_videos\\challenge_output.mp4\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}